import pickle as pkl
import argparse
import torch
from torch import nn
from collections import defaultdict
import torch.utils.data as Data
import sys, time, os, csv
import numpy as np
from bidict import bidict
from model import hotspot_model
start = time.time()


#############################################################
########################  Parameters  #######################
#############################################################
parser = argparse.ArgumentParser(description="""HOTSPOT is a python library for plasmid host prediction.
                                 HOTSPOT is a Transformer-based model and rely on protein-based vocabulary to convert DNA sequences into sentences for prediction.""")
parser.add_argument('--model_path', help='path of the folder storing the downloaded or your customized models, default: models', type=str, default='models')
parser.add_argument('--midfolder', help='folder to store the intermediate files (generated by preprocessing.py), default: temp', type=str, default='temp')
parser.add_argument('--device', help="device utilized for prediction ('gpu' or 'cpu'), default: 'gpu'", type=str, default = 'gpu')
parser.add_argument('--threads', help="number of threads utilized for prediction if 'cpu' is detected ('cuda' not found), default: 2", type=int, default=2)
parser.add_argument('--batch_size', help="batch size for prediction, default: 200", type=int, default=200)
parser.add_argument('--out', help='path to store the prediction results, default: results', type=str, default='results')
parser.add_argument('--accurate_mode', help="if this option is set to True, HOTSPOT will run in accurate mode. In accurate mode, the prediction process is slightly slower due to the activation of the MC-dropout mechanism. Additionally, besides the normal output file 'host_lineage.tsv', a supplementary TSV file named 'host_lineage_acc.tsv' will be generated. This file contains high-confidence predictions with a sacrifice of resolution, meaning that for certain inputs, the returned taxa may be at higher levels in the taxonomic hierarchy, default: False", type=str, default='False')
parser.add_argument('--mc_num', help="if the accurate mode is activated, you can use this option to specify the number of dropout-enabled forward passes for the MC-dropout mechanism, default: 100", type=int, default=100)
parser.add_argument('--min_mean', help="the minimum mean value for a prediction that will not trigger early stopping by MC-dropout, default: 0.75", type=float, default=0.75)
parser.add_argument('--max_var', help="the maximum variance value for a prediction that will not trigger early stopping by MC-dropout, default: 0.3", type=float, default=0.3)
inputs = parser.parse_args()


#############################################################
########################  Help info  ########################
#############################################################
def help_info():
    print('')
    print("""Usage of hotspot.py:
        [--model_path MODEL_PATH]   path of the folder storing the downloaded or your customized models, default: models
        [--midfolder MIDFOLDER] folder to store the intermediate files (generated by preprocessing.py), default: temp
        [--device DEVICE]   device utilized for prediction ('gpu' or 'cpu'), default: 'gpu'
        [--threads THREADS] number of threads utilized for prediction if 'cpu' is detected ('cuda' not found), default: 2
        [--batch_size BATCH_SIZE]   batch size for prediction, default: 200
        [--out OUT] path to store the prediction results, default: results
        [--accurate_mode ACCURATE_MODE] if this option is set to True, HOTSPOT will run in accurate mode. In accurate mode, the prediction process is slightly slower due to the activation of the MC-dropout mechanism. Additionally, besides the normal output file 'host_lineage.tsv', a supplementary TSV file named 'host_lineage_acc.tsv' will be generated. This file contains high-confidence predictions with a sacrifice of resolution, meaning that for certain inputs, the returned taxa may be at higher levels in the taxonomic hierarchy, default: False
        [--mc_num MC_NUM]   if the accurate mode is activated, you can use this option to specify the number of dropout-enabled forward passes for the MC-dropout mechanism, default: 100
        [--min_mean MIN_MEAN]   the minimum mean value for a prediction that will not trigger early stopping by MC-dropout, default: 0.75
        [--max_var MAX_VAR] the maximum variance value for a prediction that will not trigger early stopping by MC-dropout, default: 0.3
        """)


#############################################################
######################  Check folders  ######################
#############################################################
out_fn = inputs.midfolder
if not os.path.exists(out_fn):
    print(f"Error! The intermediate folder '{out_fn}' is unavailable. Please use the option '--midfolder' to indicate the directory where the intermediate files generated by 'preprocessing.py' are stored.")
    help_info()
    sys.exit()

mdl_fn = inputs.model_path
if not os.path.exists(mdl_fn):
    print(f"Error! The model folder '{mdl_fn}' is unavailable. Please use the option '--model_path' to indicate the folder of the downloaded or your customized models.")
    help_info()
    sys.exit()

res_fn = inputs.out
if not os.path.isdir(res_fn):
    os.makedirs(res_fn)


#############################################################
######################  Initialization  #####################
#############################################################
# device
device_opt = inputs.device
if(device_opt=='gpu'):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if(device==torch.device("cuda")):
        print("Running hotspot.py with GPU ...")
    else:
        print("CUDA is not available!", end = ' ')
else:
    device = torch.device('cpu')
if device == torch.device('cpu'):
    torch.set_num_threads(inputs.threads)    
    print(f"Running hotspot.py with CPU {inputs.threads} threads ...")

# accurate mode
def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

acc_mode = str2bool(inputs.accurate_mode)
mean_cutoff = inputs.min_mean
var_cutoff = inputs.max_var
if(acc_mode):
    mcnum = inputs.mc_num
    if(mcnum<10):
        mcnum = 10
        print('The specified number of dropout-enabled forward passes is smaller than 10! It has been set to 10 by default.')
    print(f'Running hotspot.py in accurate mode (MC-dropout activated) ...')
else:
    print(f'Running hotspot.py in normal mode ...')

batch_size = inputs.batch_size
softmax = nn.Softmax(dim=1)

feat_dict = pkl.load(open(f'{out_fn}/test_feat.dict', 'rb'))
LABELS = pkl.load(open(f'{mdl_fn}/labels.dict', 'rb'))
tree = pkl.load(open(f'{mdl_fn}/host_phylogenetic_tree.pkl', 'rb'))
parent_dict = pkl.load(open(f'{mdl_fn}/parent.dict', 'rb'))

inherit_dict = {}
for node in tree.all_nodes():
    taxon = node.identifier
    if(taxon=='Bacteria'):
        continue
    siblings = tree.siblings(taxon)
    if(len(siblings)==0):
        inherit_dict[parent_dict[taxon]] = taxon


#############################################################
#########################  Predict  #########################
#############################################################
def return_batch(sentences, labels, flag):
    X = torch.from_numpy(sentences).to(device)
    y = torch.from_numpy(labels).to(device)
    test_dataset = Data.TensorDataset(X, y)
    test_loader = Data.DataLoader(
        dataset=test_dataset,
        batch_size=batch_size,
        shuffle=flag,
        num_workers=0,  # data will be loaded in main process
    )
    return test_loader

def enable_dropout(model):
    """ Function to enable the dropout layers during test-time """
    for m in model.modules():
        if m.__class__.__name__.startswith('Dropout'):
            m.train()

level_dict = {0:'Phylum', 1:'Class', 2:'Order', 3:'Family', 4:'Genus', 5:'Species'}
CONTIGS = sorted(list(feat_dict))
final_res_dict = defaultdict(list)
early_stop_dict = {}    # plasmids that are early stopped by MC-dropout
consistency_stop = set()
for level in range(6):  # phylum, class, order, family, genus, species
    X_test = []
    labels = bidict(LABELS[level])

    # assemble dataset
    for contig in CONTIGS:
        X_test.append(feat_dict[contig])
    X_test = np.array(X_test)
    y_test = np.array([0]*X_test.shape[0])

    # load model
    model = hotspot_model(device=device, output_num=len(labels)).to(device)
    model.load_state_dict(torch.load(f'{mdl_fn}/{level_dict[level]}.pth', map_location=device))
    _ = model.eval()
    test_loader = return_batch(X_test, y_test, flag=False)

    with torch.no_grad():
        preds = []
        for step, (batch_x, batch_y) in enumerate(test_loader):
            sentence = batch_x.int()
            logit = model(sentence)
            logit = softmax(logit)
            pred = [torch.argmax(item) for item in logit]
            preds+=pred

    # accurate mode
    if(acc_mode and level>0):
        print(f'Running MC-dropout {mcnum} times at the {level_dict[level]} level ...')
        enable_dropout(model)
        dropout_predictions = []
        for i in range(mcnum):
            predictions = []
            for step, (batch_x, batch_y) in enumerate(test_loader):
                sentence = batch_x.int()
                with torch.no_grad():
                    logit = model(sentence)
                    logit = softmax(logit)
                predictions.append(logit.cpu().numpy())
            predictions = np.concatenate(predictions, axis=0)
            dropout_predictions.append(predictions)
        dropout_predictions = np.stack(dropout_predictions, axis=0)
        variance = np.var(dropout_predictions, axis=0)
        mean = np.mean(dropout_predictions, axis=0, keepdims=False)
    
    # summarize results
    idx=-1
    for i in preds:
        idx+=1
        contig = CONTIGS[idx]
        if(contig in consistency_stop):
            continue
        taxon = labels.inv[i.item()]
        if(level==0):
            final_res_dict[contig].append(taxon)
        else:
            if(parent_dict[taxon]==final_res_dict[contig][-1]):
                final_res_dict[contig].append(taxon)
            else:
                if(final_res_dict[contig][-1] in inherit_dict):
                    final_res_dict[contig].append(inherit_dict[final_res_dict[contig][-1]])
                else:
                    consistency_stop.add(contig)
        
        # check early stop with MC-dropout
        if(acc_mode and level>0):
            prob_mean = mean[idx][i.item()]
            VAR_ratio = variance[idx][i.item()]/prob_mean
            if(VAR_ratio>=var_cutoff or prob_mean<mean_cutoff):
                early_stop_dict[contig] = level


#############################################################
#########################  Results  #########################
#############################################################
tsv_w = csv.writer(open(f'{res_fn}/host_lineage.tsv', 'w'), delimiter='\t')
tsv_w.writerow(['Contig', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species'])
for contig in final_res_dict:
    tmp = ['-']*7
    tmp[0] = contig
    for i in range(len(final_res_dict[contig])):
        tmp[i+1] = final_res_dict[contig][i]
    tsv_w.writerow(tmp)

if(acc_mode):
    tsv_w_acc = csv.writer(open(f'{res_fn}/host_lineage_acc.tsv', 'w'), delimiter='\t')
    tsv_w_acc.writerow(['Contig', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species'])
    acc_res_dict = {}
    for contig in final_res_dict:
        if(contig not in early_stop_dict):
            acc_res_dict[contig] = final_res_dict[contig]
        else:
            acc_res_dict[contig] = final_res_dict[contig][:early_stop_dict[contig]]
        tmp = ['-']*7
        tmp[0] = contig
        for i in range(len(acc_res_dict[contig])):
            tmp[i+1] = acc_res_dict[contig][i]
        tsv_w_acc.writerow(tmp)

print(f'Plasmid host prediction finished! the prediction results have been saved in the folder {res_fn}.')
end = time.time()
print(f'Total running time of host prediction is {end-start}s.')
